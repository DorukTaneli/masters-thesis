@mastersthesis{birk,
    author =        "Birk Ulstad",
    title =         "Automation and Intelligent Optimisation in High Performance Sailing Boats: Supervised Learning Approach",
    month =         "May",
    year =          "2019",
    school =        "Imperial College London"
}

@mastersthesis{roman,
    author =        "Roman Kastusik",
    title =         "Automation and Intelligent Optimisation in High Performance Sailing Boats: Reinforcement Learning Approach",
    month =         "June",
    year =          "2019",
    school =        "Imperial College London"
}

@mastersthesis{stan,
    author =        "Stanislas Hannabelle",
    title =         "Automation and Intelligent Optimisation in High Performance Sailing Boats",
    month =         "September",
    year =          "2019",
    school =        "Imperial College London"
}

@mastersthesis{charles,
    author =        "Charles Metz",
    title =         "Automation and Intelligent Optimisation in High Performance Sailing Boats",
    month =         "September",
    year =          "2020",
    school =        "Imperial College London"
}

@misc{ wiki:tack,
   author = "Wikipedia",
   title = "Tacking (sailing) --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2021",
   url = "https://en.wikipedia.org/wiki/Tacking_(sailing)",
   note = "[Online; accessed 22-April-2021]"
 }
 
@misc{ pittman_awards, 
    title={2016 Pittman Innovation Awards},
    howpublished = {\url{https://www.sailmagazine.com/gear/2016-pittman-innovation-awards}}, 
    journal={Sail Magazine}, 
    year={2016}, 
    month={Jan}
 }
 
@misc{harkenAST, 
title={Harken/Jeanneau's Assisted Sail Trim (AST) Winner of Pittman Innovation Award}, 
url = {\url{https://www.harken.com/en/news/harkenjeanneaus-assisted-sail-trim-ast-winner-of-pittman-innovation-award/}}, journal={Harken Marine},
year={2020}, 
month={Aug}}

@booklet{ASTbrochure,
  title        = {Assisted Sail Trim},
  author       = {Jeanneau}, 
  address      = {32 Avenue des Sables France},
  year         = 2016,
  note         = {[Online; accessed 27-April-2021]}
}

@book{10.5555/1803899,
author = {Olivas, Emilio Soria and Guerrero, Jose David Martin and Sober, Marcelino Martinez and Benedito, Jose Rafael Magdalena and Lopez, Antonio Jose Serrano},
title = {Handbook Of Research On Machine Learning Applications and Trends: Algorithms, Methods and Techniques - 2 Volumes},
year = {2009},
isbn = {1605667668},
publisher = {Information Science Reference - Imprint of: IGI Publishing},
address = {Hershey, PA},
abstract = {The machine learning approach provides a useful tool when the amount of data is very large and a model is not available to explain the generation and relation of the data set. The Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques provides a set of practical applications for solving problems and applying various techniques in automatic data extraction and setting. A defining collection of field advancements, this Handbook of Research fills the gap between theory and practice, providing a strong reference for academicians, researchers, and practitioners.}
}

@misc{brownlee_2019, title={A Gentle Introduction to Transfer Learning for Deep Learning}, howpublished = {\url{https://machinelearningmastery.com/transfer-learning-for-deep-learning/}}, journal={Machine Learning Mastery}, author={Brownlee, Jason}, year={2019}, month={Sep}}

@article{ZHU2021104269,
title = {Investigation of transfer learning for image classification and impact on training sample size},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {211},
pages = {104269},
year = {2021},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2021.104269},
url = {https://www.sciencedirect.com/science/article/pii/S016974392100037X},
author = {Wenbo Zhu and Birgit Braun and Leo H. Chiang and Jose A. Romagnoli},
keywords = {Deep learning, Transfer learning, Image processing, Classification},
abstract = {Recent developments in deep learning have brought huge breakthroughs in the image processing area, which triggered numerous successful applications and positively impacted the current big data context of Industry 4.0. On the other hand, it is widely known that large amounts of training data are required to train a deep learning model with millions of parameters, which limits its application in many industrial applications where sufficient data resources are lacking. Transfer learning is one of the practical solutions to reduce the data required for training, which tries to reuse learned knowledge for similar tasks. Nevertheless, many technical details of transfer learning implementation are not well documented. Therefore, in this work, two datasets collected from plastics manufacturing processes were studied to investigate different transfer learning approaches and implementation details for high-performance model building under the constraint of limited available training data. Different transfer learning implementations are compared and important technical details are also discussed in this study. Through this study, the minimum number of training samples can be estimated. Transfer learning is compared with the newly developed few-shot learning approach as a brief comparative study. Finally, this work summarizes practical guidelines for the development of image classification models with limited data resources.}
}

@misc{ openai:rl-algs,
   author = "OpenAI Spinning Up",
   title = "Part 2: Kinds of RL Algorithms",
   year = "2020",
   month = "Jan",
   howpublished = "\url{https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}",
   note = "[Online; accessed 29-April-2021]"
 }
 
@misc{ddpg,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{td3,
      title={Addressing Function Approximation Error in Actor-Critic Methods}, 
      author={Scott Fujimoto and Herke van Hoof and David Meger},
      year={2018},
      eprint={1802.09477},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{sac,
      title={Soft Actor-Critic Algorithms and Applications}, 
      author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
      year={2019},
      eprint={1812.05905},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ openai:td3,
   author = "OpenAI Spinning Up",
   title = "Twin Delayed DDPG",
   year = "2020",
   month = "Jan",
   howpublished = "\url{https://spinningup.openai.com/en/latest/algorithms/td3.html}",
   note = "[Online; accessed 30-April-2021]"
}
 
@misc{ openai:sac,
   author = "OpenAI Spinning Up",
   title = "Soft Actor-Critic",
   year = "2020",
   month = "Jan",
   howpublished = "\url{https://spinningup.openai.com/en/latest/algorithms/sac.html}",
   note = "[Online; accessed 30-April-2021]"
}

@misc{sacOG,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ openai:bench,
   author = "OpenAI Spinning Up",
   title = "Benchmarks for Spinning Up Implementations",
   year = "2020",
   month = "Jan",
   howpublished = "\url{https://spinningup.openai.com/en/latest/spinningup/bench.html}",
   note = "[Online; accessed 30-April-2021]"
}

@misc{ openai:sac-code,
   author = "OpenAI Spinning Up",
   title = "Source code for spinup.algos.sac.sac",
   year = "2020",
   month = "Jan",
   howpublished = "\url{https://spinningup.openai.com/en/stable/_modules/spinup/algos/sac/sac.html}",
   note = "[Online; accessed 30-April-2021]"
}

@misc{ TF:IG,
   author = "Tensorflow",
   title = "Integrated Gradients",
   year = "2021",
   month = "Mar",
   howpublished = "\url{https://www.tensorflow.org/tutorials/interpretability/integrated_gradients}",
   note = "[Online; accessed 30-April-2021]"
}

@misc{ TF:TL,
   author = "Tensorflow",
   title = "Transfer learning and fine-tuning",
   year = "2021",
   month = "Apr",
   howpublished = "\url{https://www.tensorflow.org/tutorials/images/transfer_learning}",
   note = "[Online; accessed 30-April-2021]"
}

@article{IGpaper,
  author    = {Mukund Sundararajan and
               Ankur Taly and
               Qiqi Yan},
  title     = {Axiomatic Attribution for Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.01365},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.01365},
  archivePrefix = {arXiv},
  eprint    = {1703.01365},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SundararajanTY17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ img:mainsail-shape-controls,
   author = "Victoria Sailing School",
   title = "Prepping for Mountain Gusts",
   year = "2020",
   month = "Feb",
   howpublished = "\url{https://victoriasailingschool.com/index.php/captains-log/164-prepping-for-mountain-gusts}",
   note = "[Online; accessed 4-May-2021]"
}

@misc{ img:mainsail-trim-back,
   author = "Toby Heppell",
   title = "Light wind Sail Trim",
   journal = "Sailing Today",
   howpublished = "\url{https://www.sailingtoday.co.uk/practical/sailing-skills/sailtrim/}",
   note = "[Online; accessed 4-May-2021]"
}

@misc{ img:telltales,
   author = "John Jamieson",
   title = "How to Sail Faster with Mainsail Leech Telltales",
   journal = "SkipperTips",
   howpublished = "\url{https://www.skippertips.com/public/35.cfm}",
   note = "[Online; accessed 4-May-2021]"
}
