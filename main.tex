\documentclass[12pt,twoside]{report}
\usepackage{parskip}
\usepackage{comment}
\usepackage{wrapfig}
\usepackage{arev}
\usepackage[table]{xcolor}
\usepackage{gensymb}
\setlength{\parindent}{2em}  % indentation of paragraph
\usepackage{float}

\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Definitions for the title page
% Edit these to provide the correct information
% e.g. \newcommand{\reportauthor}{Timothy Kimber}

\newcommand{\reporttitle}{Automation and Intelligent Optimisation in High Performance Sailing Boats}
\newcommand{\reportauthor}{Doruk Taneli}
\newcommand{\supervisor}{Dr. Pedro Baiz}
\newcommand{\degreetype}{Advanced Computing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% load some definitions and default packages
\input{includes}

% load some macros
\input{notation}

\date{September 2021}

\begin{document}

% load title page
\input{titlepage}


% page numbering etc.
% later: uncomment page numberings
%\pagenumbering{roman}
%\clearpage{\pagestyle{empty}\cleardoublepage}
%\setcounter{page}{1}
\pagestyle{fancy}

\begin{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Your abstract.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}
Comment this out if not needed.

\clearpage{\pagestyle{empty}\cleardoublepage}

\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 


\clearpage{\pagestyle{empty}%\cleardoublepage
}
%\pagenumbering{arabic}
%\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}


Modern sailboats are built by combining bleeding edge science from many areas, including material science for lighter and more durable materials, aero and hydro dynamics for the most efficient designs, and latest sensors for most accurate information. One area that stayed underdeveloped compared to the other parts of the boat is the autopilot. Although autopilot systems have also improved, they are still comparatively crude and low performing.

Shorthanded races are one type of popular competition where there are either one or two crew members, as opposed to full crews that can go up to around ten people. Autopilots are used extensively during these shorthanded races, steering the boat for more than 95\% of the time, while the crew handles other boat work or personal sustenance. Despite carrying out more than 95\% of the steering, autopilots only perform at 80\% of the capability of a professional skipper \cite{roman}. Therefore there is a huge potential to gain race winning advantage in shorthanded competitions by improving the autopilots. Jack Trigger \cite{trigger-racing}, who competes in shorthanded races, is providing the data from his boat sensors which makes this project possible. 

The goal of this project is to realize this potential race winning advantage by creating a Machine Learning model, trained by Reinforcement Learning, which will predict the optimal rudder angle using onboard boat sensors. To achieve that, this project will continue the work of former Imperial students and the employees of the partner company, The Data Analysis Bureau (T-DAB) \cite{t-dab}. Extensive work have been done on this project since 2018, mostly focusing on cleaning and preprocessing the available data, plus creating Machine Learning models that predicts the state of the boat, which will be referred as state estimator models in the rest of this report.

I, Doruk Taneli, will continue their work, and using the data and code they prepared, I will further improve the state estimator models, implement an OpenAI Gym environment in which the Reinforcement Learning will take place, compare the performance of state-of-the-art RL algorithms on this environment, then draw conclusions. If the simulation environment can reproduce the interactions between the rudder, the boat, and the sea realistically enough, the Reinforcement Learning algorithm can potentially learn how to steer a boat better than a human professional.

%\section{Objectives}

%\section{Outcomes}

%\section{Report Structure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background}

\begin{wrapfigure}{r}{0.50\textwidth}
\vspace{-11cm}
\centering
\includegraphics[width = 0.45\textwidth]{figures/sailing/sailboat-parts.png}
\caption{Sailboat parts \cite{sail-parts}}
\label{fig:sail-parts}
\end{wrapfigure}

\section{Sailing Background}
Sailboats work by utilizing the balance of forces created between the sails and the wind as the driving force, the keel/rudder and the sea for controlling the boat, plus the gravity for countering the heel. There are countless online resources to learn about the details of how sailboats work. Here, I will focus on the parts that are important for the project.

\subsection{Basics of Sailing}
Many might think that sailboats move with the wind's pushing on the sail. Although this is true for some wind angles, most of the time the sails work like airplane wings utilizing Bernoulli's Principle. To put it simply, Bernoulli's principle \cite{wiki:bernoulli} states that increasing flow speed in fluids corresponds to decreasing pressure, and vice versa. The shape of the sails resemble an airplane wing. Because of its shape, the air travels faster on one side than the other, which creates a pressure difference, and results in a net force that drives the boat forward. Using the Bernoulli Principle, a sailboat is able to travel in much wider wind angles, compared to what would be possible by using wind push only.

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\hsize]{figures/sailing/sail-bernoulli.jpg}
\caption{Visualization of Bernoulli Principle: (a)Airplane wing, (b)Sail \cite{bernoulli}}
\label{fig:bernoulli}
\end{figure}

\subsection{Point of Sails}
The direction of the boat compared to the wind is called the point of sails. As can be seen in Figure \ref{fig:points-of-sail}, sailboats can go in almost all angles with respect to the wind, except from straight into the wind.

\begin{figure}[h]
\centering
\includegraphics[width = 0.55\hsize]{figures/sailing/PointsOfSail.png}
\caption{Point of Sails \cite{img:sailing-tack-gybe}}
\label{fig:points-of-sail}
\end{figure}

In order to make progress towards the wind, one needs to sail close hauled as seen in Figure \ref{fig:points-of-sail}, and make repeated turns with respect to the wind, known as tack. During a tack, the boat changes direction by turning its head towards and through the wind so that the direction from which the wind blows changes from one side of the boat to the other \cite{wiki:tack}. Jibe is similar to tack, but it is used while sailing downwind, and the boat changes direction by heading away instead of towards the wind. Visualizations of tack and jibe can be seen in Figure \ref{fig:tack-jibe}. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/sailing/tack.png}
        %\caption{tack \cite{img:sailing-tack-gybe}}
        \label{fig:tack}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/sailing/jibe.png}
        %\caption{jibe \cite{img:sailing-tack-gybe}}
        \label{fig:jibe}
    \end{subfigure}
    \caption{Tack (left) and Jibe (right) \cite{img:sailing-tack-gybe}}
    \label{fig:tack-jibe}
\end{figure}

Since tacks and jibes require readjustments in sails, an autopilot should not do these manoeuvres unless specifically instructed by the skipper. In addition, the state of the boat differs a lot during tacks and jibes compared straight cruising, which confuses the state estimators we are trying to build. Stanislas removed tacks from the dataset the models were trained on, and achieved significant performance increase (cf. Section \ref{sec:Stan}).

\subsection{Polar Speed}

Although the boats can sail in many angles with respect to the wind, there are optimal angles to sail with due to the design of the boat. A polar plot, which plots the performance of a boat with reference to the true wind angle, is a helpful tool to judge a boat's optimal angles. The polar plot for Concise 8 can be seen in Figure \ref{fig:polar-plot}. Looking at the polar plot, we can see that the best upwind angle is around 45\degree, whereas the best downwind angle is around 150\degree. In his project, Roman incorporated this optimal degree and speed information in Reinforcement Learning reward.

\begin{figure}[h]
\centering
\includegraphics[width = 0.85\hsize]{figures/sailing/polar-plot.png}
\caption{Concise 8 Polar Plot \cite{stan}}
\label{fig:polar-plot}
\end{figure}

\subsection{Elements Affecting Boat Heading}
\subsubsection{Rudder}
The most important element that affects the boat heading is the rudder, whose main purpose is to steer the boat. It works by displacing water at the back of the boat, which creates a force that turns the boat around its center, the keel. Although it is the easiest way to control the boat, moving the rudder creates drag and slows down the boat, so it is not preferable to use it excessively.

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{figures/sailing/rudder.jpg}
\caption{How rudder works \cite{rudder}}
\label{fig:rudders}
\end{figure}

\subsubsection{Boat Design and Sail Trim}

\begin{wrapfigure}[10]{r}{0.3\textwidth}
\vspace{-1cm}
\centering
\includegraphics[width = 0.15\textwidth]{figures/sailing/tork.jpg}
\caption{Balance of torque across keel}
\label{fig:keel-tork}
\end{wrapfigure}

If there is more force acting from the front of the keel than from the back of the keel, the boat will naturally turn. This is taken into account when designing the boat, by carefully calculating the area of fore and main sails, position of mast and keel, etc. The balance of these forces can also be altered after the boat is manufactured. For example, many high performance sailing boats have features to adjust the position, angle and bend of the mast. Furthermore, this balance can even be adjusted on the go, by trimming the fore and main sails individually.

\subsubsection{Heel}
Heeling in sailing means the tipping of the sailboat to one side, also known as Roll in boating or aviation. When the boat heels, the boat wants to turn towards the wind. Sailboats heel more as the wind speed increases. This is also factored in during the design of the boat, because continually countering this turn with rudder would significantly slow the boat down.

\begin{figure}[h]
\centering
\includegraphics[width = 0.7\textwidth]{figures/sailing/boat-pitch-roll-yaw.png}
\caption{Wave affecting boat \cite{img:pitch-roll-yaw}}
\label{fig:pitch-roll-yaw}
\end{figure}

\subsubsection{Waves}
Waves affect the heading in two ways. First, the momentum of the waves hitting the boat from different angles changes the course of the boat. Second, as the boat moves through the waves, the roll and the pitch of the boat changes, which affects the boat's centre of gravity and how sails interact with wind, resulting in a change in heading.

As we can see, there are a lot of factors that affect the boat heading, and it can't be controlled solely by rudder. This knowledge affected the decisions made in the later parts of the project, for example the Reinforcement Learning environment.


\section{State of the Art Autopilots}

The common consumer autopilots work in a very basic way. It either focuses on the boat's heading, using the data from magnetic compass; or focuses on the apparent wind, using the data from the wind sensor usually found at the top of the mast. The autopilot system compares the current reading and the goal reading, and every time the boat diverges from the goal(e.g., by wind or waves), the autopilot compensates by moving the rudder in the opposite way. 

\begin{figure}[h]
\centering
\includegraphics[width = 0.65\textwidth]{figures/other/autopilot.jpg}
\caption{A typical autopilot system \cite{img:autopilot}}
\label{fig:autopilot}
\end{figure}

The focus of common consumer autopilots is to keep the boat on the right course. There are also more advanced options, gaining popularity in the last few years, that focus more on performance and racing. These autopilots have some features that imitates how a professional skipper would steer a boat in certain situations. For example: B\&G autopilots \cite{bandg} have gust response feature that quickly recovers from changes in wind, NKE autopilots \cite{nke} have surf mode that promotes the use of waves in downwind angles \cite{yachting_world_2020}, Raymarine autopilots \cite{raymarine} decide on whether to use apparent or true wind depending on wind angle \cite{cruising_world_2019}.

However, these features are all rule based, usually require manual sensitivity tuning, and does not make use of the recent advancement in computing: machine learning. Madintec is the only company that currently uses machine learning in their autopilots for foiling sailboats \cite{madintec}. Foiling sailboats move at extreme speeds, so getting real-time data does not provide enough time for optimal rudder angle calculation. Madintec utilizes a machine learning model to predict the future boat state, and uses that prediction for autopilot decision making \cite{madintec-eric}.

There are no commercially available autopilots that utilize machine learning any further. One notable attempt to use Reinforcement Learning in Sailboat autopilots was done by the RoboSail project \cite{robosail1}. The authors attempted to make a fully autonomous sailing system based on RL, but concluded that it would need several trips around the world for the algorithm to converge \cite{robosail2}. The Robosail team then took on the prevalent approach of rule based autopilots, but let the RL algorithm decide on the parameters and sensitivities instead \cite{robosail3}.

Thanks to the data from Trigger Racing, plus the work of previous students, T-DAB and Imperial College London employees and supervisors, this project aims to tackle the previously unfulfilled challenge of Reinforcement Learning on real-world sailboat autopilots.

\section{Literature Review: RL Algorithms}
In this section, the modern Reinforcement Learning algorithms and the suggested algorithm to be used for our use case in this project is discussed.

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/RL algorithms.png}
\caption{A non-exhaustive taxonomy of modern RL algorithms \cite{openai:rl-algs}}
\label{fig:rl-algs}
\end{figure}

An introductory taxonomy of the modern RL algorithms can be seen in Figure ~\ref{fig:rl-algs}. There are two main classes of RL algorithms, Model-Based and Model-Free. In Model-Based algorithms, the algorithms have either access to the environment model, or it learns the environment model. The problem with this branch of algorithms is that usually, the ground truth of the environment is not readily available to the agent. The agent has to learn a simulated environment, then performs poorly on the real environment. This is specifically the case for our project. Furthermore, Model-Based algorithms have not been as extensively developed and tested as the Model-Free algorithms \cite{openai:rl-algs}. Because of these downsides of Model-Based algorithms, I will focus on the Model-Free algorithms for this project.

In Model-Free RL, there are two main techniques: Policy Optimization and Q-Learning. Algorithms such as DDPG, TD3, and SAC - which are state of the are and best suits our use case - uses a hybrid approach of both of these techniques.
DDPG is the first of these algorithms that was developed in 2015, and can be seen as an adaptation of Deep Q-Learning for continuous action spaces \cite{ddpg}. TD3 and SAC were both developed around the same time in 2018. They utilize different tricks to improve DDPG.

\subsection{TD3}
DDPG is prone to overestimating Q-values. Twin Delayed DDPG (TD3) attempts to solve this issue with three tricks: \cite{openai:td3}

\begin{enumerate}
  \item \textbf{Clipped Double-Q Learning:} Instead of one in DDPG, TD3 learns two Q functions, and uses the lesser Q value in the Bellman error loss functions.
  \item \textbf{“Delayed” Policy Updates:} TD3 updates the policy and target networks less frequently than the Q-function. The original paper recommends one policy update for every two Q-function updates.
  \item \textbf{Target Policy Smoothing:} TD3 adds noise to the target action, to make it harder for the policy to exploit Q-function errors by smoothing out Q along changes in action.
\end{enumerate}

In the original TD3 paper, Fujimoto et al. claims that TD3 outperforms the state of the art in every OpenAI gym task tested \cite{td3}. The comparison of the algorithms in different environments can be seen in Figure~\ref{fig:td3-comparisons}.

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/td3 comparison.png}
\caption{Performance comparison of RL algorithms in TD3 paper \cite{td3}}
\label{fig:td3-comparisons}
\end{figure}


\subsection{SAC}
Instead of deterministic policies used in DDPG and TD3, SAC uses stochastic policies. Thus, it is a bridge between stochastic policy optimization and DDPG-style approaches. Like TD3, it uses a few tricks to improve DDPG: \cite{openai:sac}

\begin{enumerate}
  \item \textbf{Entropy Regularization:} The policy is trained to maximize a trade-off between expected return and entropy. This is closely related to exploration-exploitation trade-off: higher entropy results in more exploration, which can accelerate learning and prevent converging to bad local optimum.
  \item \textbf{Next-State Actions:} In SAC, the next-state actions used in the target come from the current policy instead of the target policy.
  \item \textbf{Clipped Double-Q Learning:} Like TD3, SAC makes use of Clipped Double-Q Learning.
  \item \textbf{Target Policy Smoothing:} Although there is no explicit target policy smoothing, since SAC uses a stochastic policy, the noise from the randomness achieves a similar effect.
\end{enumerate}

In the original SAC paper, Haarnoja et al. claims that SAC outperforms the state of the art algorithms in sample-efficiency, asymptotic performance, and stability \cite{sacOG}. The comparison of the algorithms in different environments can be seen in Figure~\ref{fig:sac-comparisons}.

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/sac comparison og.png}
\caption{Performance comparison of RL algorithms in SAC paper \cite{sacOG}}
\label{fig:sac-comparisons}
\end{figure}

\subsection{Algorithm of Choice}
Interestingly, both SAC and TD3 authors claim that they perform better than each other in their own papers. So a third party benchmark is necessary to be able to compare the two algorithms. A comparison of OpenAI PyTorch implementations of TD3, SAC, and few other algorithms can be seen in Figure \ref{fig:openAI-comparisons}.

\begin{figure}[h]
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/OpenAI benchmarks/halfcheetah pt.png}
         \caption{HalfCheetah-v3}
     \end{subfigure}
     \quad
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/OpenAI benchmarks/hopper pt.png}
         \caption{Hopper-v3}
     \end{subfigure}
     \quad
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/OpenAI benchmarks/walker pt.png}
         \caption{Walker2d-v3}
     \end{subfigure}
     \quad
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/OpenAI benchmarks/ant pt.png}
         \caption{Ant-v3}
     \end{subfigure}
        \caption{Performance comparison of OpenAI implementations of RL algorithms \cite{openai:bench}}
        \label{fig:openAI-comparisons}
\end{figure}

As can be seen in Figure \ref{fig:openAI-comparisons}, TD3 and SAC perform closely to each other, with SAC having a slight advantage over TD3. However one should note that OpenAI implementation of SAC have slight variations that bring it closer to TD3 \cite{openai:sac-code}.

The advantage of TD3 is that it performs really close to SAC, with less complexity and less hyperparameters to tune. However, the second iteration of SAC from the original authors automatically tunes the problematic temperature hyperparameter, reducing the problem of hyperparameter tuning, making the algorithm more stable among different seeds and environments, and performs well even in the worst case, which is important for real life use cases \cite{sacOG}. 

Because of these reasons, the suggested algorithm to be used for the Reinforcement Learning Approach is Soft Actor-Critic (SAC).

\subsection{Recent Advancement: Truncated Quantile Critics}

Truncated Quantile Critics (TQC) is a novel algorithm whose original paper was published in May 2020 \cite{tqc-paper}. TQC aims to solve the overestimation bias in continuous off-policy learning by combining three ideas: distributional representation of a critic, truncation of critics prediction, and ensembling of multiple critics. The authors claim that TQC outperforms the current state of the art in all the environments they tested. The comparison of the algorithms can be seen in Figure \ref{fig:tqc-comparison}.

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/tqc comparison.png}
\caption{Average performance of RL algorithms on MuJoCo Gym Environments \cite{tqc-paper}}
\label{fig:tqc-comparison}
\end{figure}

TQC is not as thoroughly tested as the current state of the art, but it shows promising results, especially in the harder environments. Although it is in beta, there is an implementation of TQC publicly available. Therefore, this new advancement in continuous RL algorithms will definitely be incorporated in this project.

\section{Previous Work}
The "Automation and Intelligent Optimisation in High Performance Sailing Boats" project started in 2019. Birk Ulstad and Roman Kastusik started working on the project simultaneously. Birk Ulstad took the Supervised Learning Approach, whereas Roman Kastusik took the Reinforcement Learning Approach to the problem. Following their work, Stanislas Hannabelle continued working on the supervised learning approach in late 2019. In 2020, Charles Metz continued the Reinforcement Learning work of Roman Kastusik. Finally, Thomas Ryder continued Charles work before I picked up the project. A very brief summary of everyone's work is presented below.
%I, Doruk Taneli, will be picking up where Birk, Roman, Stanislas, and Charles left off and  further improve the project.

\subsection{Birk Ulstad}
Birk's goal was to develop a supervised machine learning model that predicts the rudder angle set by Jack Trigger on the Concise 8 boat, using the previous data recorded during races by the existing sensors on the boat \cite{birk}.

Birk Ulstad converted the available raw, partially corrupted data to processable csv data. He then cleaned the csv data by removing the irrelevant and corrupted parts, analysing outliers and applying smoothing. Next, he normalized, reframed, and downsampled the data to get it ready for the supervised learning model.

\begin{figure}[h]
\centering
\includegraphics[width = 0.7\hsize]{figures/Birk Ulstad LSTM prediction.png}
\caption{Birk Ulstad's LSTM prediction methods}
\label{fig:birk lstm}
\end{figure}

For the model, Birk preferred a two stateful LSTM layers, each followed by a dropout layer to prevent overfitting. The prediction plan of the model can be seen in Figure~\ref{fig:birk lstm}. The original plan was to use both past values of the feature set until time t-1 (blue arrows) and the current values at time t (red arrows) to predict the rudder angle. However he only managed to get blue arrow predictions to work, and used those while discussing his results.

Birk concluded that his model architecture is able to predict the rudder angle produced by a human within a couple of degrees. His other notable observations were: 
\begin{itemize}
  \item The model is able to predict the autopilot's rudder angle with much less error compared to a human's rudder angle. Birk explained this as "Learning a univariate rule-based function [of an autopilot] is easier than learning the multivariate function that maps human sensory input to human rudder output".
  \item Downsampling the available data to 5 Hz from 25 Hz is a good middle ground between training time and RMSE. 
  \item An input sequence length between 5-15 seconds provides an optimal trade-off between training time and prediction accuracy.
\end{itemize} 

\subsection{Roman Kastusik}
Roman's objective was to utilize reinforcement learning to increase the autopilots' performance, potentially beyond human level. To achieve this, he trained an LSTM state estimator to simulate the boat's behavior using Jack Trigger's race data, and created a reinforcement learning algorithm that would interact with said simulation environment \cite{roman}.

\begin{wrapfigure}{R}{0.55\textwidth}
\centering
\includegraphics[width = 0.54\textwidth]{figures/roman data flow.png}
\caption{Roman Kastusik's RL data flow}
\label{fig:roman dataflow}
\end{wrapfigure}

Roman started with some data analysis, data cleaning, and scaling on Jack Trigger's race data. He then used this data to train the simulation environment that would be used for the reinforcement learning algorithm. The data flow around the simulation environment and the reinforcement learning algorithm can be found in Figure \ref{fig:roman dataflow}.

He also did research about the recent advancements in reinforcement learning, and created an RL algorithm utilizing Deep Deterministic Policy Gradients, Actor-Critic Networks and Experience Replay.

Roman concluded that due to the poor performance of the simulation environment, it was not possible to realize the full potential of the reinforcement learning algorithm. Charles Metz later continues his work and improves the simulation environment.

\subsection{Stanislas Hannabelle} \label{sec:Stan}
Stanislas' goal was to improve the results of Birk Ulstad's supervised learning approach to the problem. He further cleaned the dataset using a tack\footnote{Tacking is a sailing maneuver where the boat changes direction by turning its head towards and through the wind so that the direction from which the wind blows changes from one side of the boat to the other, allowing progress in the desired direction \cite{wiki:tack}.} detection system, did hyperparameter and bayesian optimization, and compared GRU and LSTM models. He was able to reduce the Root Mean Squared Error from 3.493 degrees of Birk's final model to 1.096 degrees, and reduced the computational time needed for rudder angle prediction \cite{stan}.

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\hsize]{figures/stan results.png}
\caption{Stanislas Hannabelle's improvements on supervised learning approach}
\label{fig:stan results}
\end{figure}

Stanislas further cleaned the available dataset by training a classifier to remove tacks, and manually removing the abnormal sailing conditions such as extremely light wind. With the new dataset, he performed the grid search shown in Table \ref{tbl:stan grid} for best sampling frequency (Hz) and input sequence length (seconds). He then performed bayesian optimization for LSTM and GRU models for 1Hz-5s and 5hz-2s parameters. After training and testing with the best hyperparameters he found, Stanislas got the results in Figure \ref{fig:stan results}.

\begin{table}[h]
\centering
\includegraphics[width=\linewidth]{figures/stan grid search.png}
\caption{validation RMSE for sampling frequency and input length combinations}
\label{tbl:stan grid}
\end{table}

With his best model 'GRU 5Hz-2s', Stanislas reduced the testing RMSE of Birk's model by approximately 68\% while cutting the required training time in half. Stanislas' model was able to predict the rudder angle produced by a human by around 1 degree. His other success was to reduce the computational time needed for rudder angle prediction so that the model can be implemented live in onboard autopilots.

\subsection{Charles Metz}
Charles' goal was to improve the state estimator model Roman suggested, so it can reliably reproduce the behaviour of a sailing boat in its sea environment. His main idea was that instead of using 1 model to predict \emph{n} sea and boat features like Roman, he used \emph{n} models to predict \emph{n} different features, which lead to very significant improvement \cite{charles}.

\begin{wraptable}{R}{0.55\textwidth}
\centering
\includegraphics[width=0.54\textwidth]{figures/charles results.png}
\caption{Charles' prediction method results}
\label{tbl:charles results}
\end{wraptable}

Charles had a new dataset available, so he started by applying similar cleaning and preprocessing steps to this new dataset. He noticed that some of the features can be derived mathematically from other features such as true wind, apparent wind, and boat speed. He decided to calculate those features mathematically, then trained \emph{n} separate models for \emph{n} remaining features. He tried 2 different models, model 1 has two final dense layers whereas model 2 has only one final dense layer.

He concluded that in general, deterministic mathematical derivations has the least error, followed by model 2, then model 1, and lastly single model for \emph{n} features. He tested model 2 in only some of the features, but it performed better in every feature tested. Error rate of different prediction methods for some of the boat features can be seen in Table \ref{tbl:charles results}. His other notable finding was that mathematical formulas do not always agree with the sensor data, which indicates that something might be wrong on the boat sensors/algorithms. Nevertheless, Charles envisions that after \emph{n} models for \emph{n} features are individually optimised, they can be integrated into a reinforcement learning framework.

\subsection{Thomas Ryder}

Following Charles' project, T-DAB employee Thomas Ryder carried on his work. Thomas' goal was to create a full pipeline which would create \emph{n} separate state estimator models, given the dataset in csv format. Charles had worked on his project using Jupyter Notebooks. Thomas converted those notebooks into concise Python scripts, plus incorporated bayesian optimization into each of the \emph{n} models like Charles suggested as a future work. Thomas' scripts now consists of the following parts, explained very briefly below:

\begin{enumerate}
  \item \textbf{Preprocessing:} Rename and select columns, convert angles to radians, scale, label tacks, split into train-validation-test segments, and downsample the data.
  \item \textbf{Optimisation:} Run Bayesian optimization for each feature within the parameters given in the config file.
  \item \textbf{Training:} Train an LSTM network with optimized hyperparameters for each feature given in the config file. Log the training history data.
  \item \textbf{Evaluation:} Make predictions using the test data, then calculate MAE and RMSE. Print information about trained models.
\end{enumerate}

According to Charles' findings of Model 2 working better on all 4 features tested, Charles decided to use Model 2 with one less final dense layer for all 18 features.

The scripts are structured better than Charles' notebooks, plus they are much easier to understand and use. However, there are some problems and tests that need to be tackled before the final models that will be used for the Reinforcement Learning Environment can be produced.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\chapter{Progress}
%\input{Chapters/progress}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Contribution}

\section{Available Datasets}

There are 7 datasets available for use in this project. Substantial work have been done by previous students for converting, cleaning and preprocessing the datasets. Curated information about the datasets can be found in Figures \ref{tab:datasets-practical} and \ref{tab:datasets-factual}. The information about Team Ocean dataset is recently recieved, it was referred as transat\_1 in previous student reports. 

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|l|c|}
\hline
\textbf{Dataset Name} & \textbf{Boat Name} & 
\textbf{\begin{tabular}[c]{@{}l@{}}Original\\Format\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Original\\Length[h]\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Cleaned\\Length[h]\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Tack\\Detection\end{tabular}} \\ \hline
RDR\_nkz    & \multirow{4}{*}{Concise 8}    & .nkz & 16    & 16    & $\ballotx$        \\ \cline{1-1} \cline{3-6}
RDR\_adrena &                               & .csv & 306   & -     & $\ballotx$        \\ \cline{1-1} \cline{3-6}
DHREAM 18   &                               & .log & 64.5  & 64.5  & $\ballotx$        \\ \cline{1-1} \cline{3-6} 
Atlantic    &                               & .nkz & 290.9 & 228.7 & $\ballotcheck$    \\ \hline
DHREAM 20   & VMB                           & .nkz & 70    & 6     & $\ballotx$        \\ \hline
Team Ocean  & Time for Oceans               & .nkz & 383.5 & 63.3  & $\ballotcheck$    \\ \hline
transat\_2  & \textit{unknown}              & .nkz & 387.5 & -     & $\ballotx$        \\ \hline
\end{tabular}
\caption{Practical information about available datasets}
\label{tab:datasets-practical}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Dataset Name} & \textbf{Boat Name}         & \textbf{Boat Class}       & \textbf{Race}          & \textbf{Year} \\ \hline
RDR\_nkz              & \multirow{4}{*}{Concise 8} & \multirow{5}{*}{Class 40} & Route du Rhum          & 2018          \\ \cline{1-1} \cline{4-5} 
RDR\_adrena           &                            &                           & Route du Rhum          & 2018          \\ \cline{1-1} \cline{4-5} 
DHREAM 18             &                            &                           & DHREAM Cup             & 2018          \\ \cline{1-1} \cline{4-5} 
Atlantic              &                            &                           & \textit{boat delivery} & 2019          \\ \cline{1-2} \cline{4-5} 
DHREAM 20             & Virgin Media Business      &                           & DHREAM Cup             & 2020          \\ \hline
Team Ocean            & Time for Oceans            & \multirow{2}{*}{IMOCA 60} & Transat Jacques Vabre  & 2019          \\ \cline{1-2} \cline{4-5} 
transat\_2            & \textit{unknown}           &                           & Transat Jacques Vabre  & 2019          \\ \hline
\end{tabular}
\caption{Factual information about available datasets}
\label{tab:datasets-factual}
\end{table}


\section{State Estimator Scripts}
In this section contributions related to the state estimator scripts that Charles and Thomas first created will be described.

\subsection{Initial Improvements}

\subsubsection{State Estimator Bug}
When the project was handed over from Thomas, there was an error causing bug in the scripts that caused the scripts to halt without producing any results. Working together with Thomas, the problem was found to be the difference in the dataset rows that preprocessing scripts created, and the rows that optimization scripts were expecting. After fixing the bug, the scripts started working as expected in local and Azure cloud machines.

\subsubsection{Data Store}
The scripts are using local csv files as input. There was a plan to switch to using cloud databases, but the switch to databases were postponed due to the following reasons:

\begin{itemize}
  \item \textbf{Cost:} There isn't any available infrastructure in T-DAB to host the database. So, Microsoft's time-series database, InfluxDB was the choice of Database. However, keeping the database online on InfluxDB costs money.
  \item \textbf{Complexity:} The switch to cloud database adds complexity to both workflow and the code. The preprocessing code previous students have spend most of their time on work with csv files. Those csv files needs to be processed separately, uploaded to cloud database, and then the same data needs to be pulled from the database with specific querying to have the same structure with the csv files, then be fed as input to the rest of the scripts.
  \item \textbf{Time:} It will take time to implement changes required to switch to cloud databases. That time is better spend on the RL portion of the project instead.
  \item \textbf{No significant advantage:} Currently, there is no significant advantage of using stand-alone cloud database that will justify the cost, complexity, and time spent. We do not have any constant flow of data, or the need for regular analysis or reporting.
  \item \textbf{A better alternative:} Currently, the race data is stored on the company SharePoint. A quick and easy way to download this data on Azure Cloud Machines was found, using a single \textit{wget} command from the terminal. This eliminates the biggest drawback of using local csv files, which is manually downloading and uploading large files. Plus it doesn't have any added cost or complexity.
\end{itemize}

\subsubsection{Tack Detection}
As mentioned on section \ref{sec:Stan}, when Stanislas removed the found tacks from the dataset and retrained the state estimator model, he achieved substantial improvement in the model's test results. 

To realize this improvement on our new optimized models, the scripts were modified to take the selected dataset \textit{Atlantic}'s tack bounds as input, and remove them from the train-validation-test sets. The tack bounds for Atlantic dataset were stored in a different format, which required some change in the code.

It is suggested to incorporate Stan's tack detection models into the script pipeline. This way, the user would not have to provide the tack info themselves, the script will automatically find and remove them. This would also alleviate the problem of different tack bound formats. (cf. Future Work)

\subsection{Data Split Concern}

There are two proposed ways of splitting the dataset into training, validation, and testing sets; named as \emph{Normal} and \emph{Segment} by Thomas. The Normal split method allocates the first 60\% of the data to training, next 20\% to validation and the last 20\% to testing. The Segment split method on the other hand, first splits the dataset into continuous segments separated by unusable areas such as tacks. Then each of those segments are individually split into train-validation-test using 60-20-20 split and then concatenated together.

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/Contribution/Normal Split.png}
\caption{Normal Split}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width = \hsize]{figures/Contribution/Segment Split.png}
\caption{Segment Split}
\end{figure}

The data in the available datasets are logged chronologically. The nuance is that the weather and sea conditions change during the course of the races. In order to train the models on all the different sea and weather conditions, Charles has used the segment split method, as if he had used the normal split method, the models couldn't have been trained on the conditions present towards the end of the race.

Charles achieved good results using the segment split. However, one recent concern about segment split is whether it causes data leak. When using the segment split, the test data is not truly held-out. The models are trained on data that is very similar to the ones used in validation and test sets. Therefore we cannot test the performance of the models on how they would perform on unseen data.

The initial plan was to create two sets of models with segment and normal split methods. The resulting models would then be compared if there is a considerable difference in the error metrics. Then, Eric informed me that although undocumented in his report, Charles already compared the two split methods, and observed significantly worse results in normal split.

On a discussion with Eric Topham and Pedro Baiz, it was decided that the performance drop was due to the models not having a chance to learn about the conditions present at the end of the race. To test how the models would perform on unseen data, we will test the data trained on one race on another race. This is called the Transferability Experiment and the details can be found in section \ref{section:transferability}.

\subsection{Efficiency Experiment}
At the beginning of the project, some initial tests were made to make sure the scripts were working fine on local and Azure cloud computers. It was noticed that with a small test dataset, running the scripts on CPU took shorter than running them on GPU. CTO of T-DAB, Ivan Scattergood suggested testing whether this was caused by the bigger overhead of GPU, or the scripts were straight up better optimized for CPU.

If it is just due to the multiprocessing overhead, running larger datasets on GPU should take shorter than CPU. But if it doesn't, we can conclude that the scripts are better optimized for CPU.

Therefore a series of experiments were started, trying to find the most efficient way to run the scripts; whether on single-core CPU, multi-core CPU, or GPU. Plus trying to estimate the total amount of time it would take to produce the state estimator models.

\subsubsection{Current Information}
\begin{itemize}
  \item We aim to produce 18 different state estimators. Producing each one is independent from others. They differ slightly in training time, due to the randomness of bayesian optimization and different resulting hyperparameters.
  \item With a small test dataset, using CPU takes shorter than using GPU.
\end{itemize}

\subsubsection{Hypothesis}
Running the scripts on GPU take longer with the small test dataset because of the overheads. Using bigger datasets will make GPU more efficient than CPU.

\subsubsection{Side Goal}
Predict how long the full script will take to produce all 18 models.

\subsubsection{Experimental set up and method}
\begin{enumerate}
    \item Do test runs on single threaded cpu, multi-threaded cpu, and gpu; with a small dataset and smaller optimization search space.
    \item Redo the experiments with 2x and 10x amount of data to see how it affects the runs.
    \item Lastly, test with full optimization search space with the better processing unit to estimate how long the full run will take.
\end{enumerate}

Speed\_ov\_ground was picked as the feature to train models on, as it has medium error rate in previous iterations of the models compared to the other features. It is expected to be a good example to infer how long the full run will take.

For CPU Tests, the default Azure compute instance “Standard\_DS3\_v2” with 4 cores, 14GB RAM, 28GB storage will be used.

For GPU Tests, the Azure-recommended “Standard\_NC6” with 6 cores, 56GB RAM, 380GB storage will be used.

\subsubsection{Assumptions}
\begin{itemize}
  \item Azure Mazhine Learning Computing units are consistent and does not fluctuate in performance 
  \item RAM does not have an effect on performance
\end{itemize}

\subsubsection{Results}

First of all, one should note the time needed is variable because of the randomness in Bayesian Optimization, but it should give us an idea of how long it will take.

As can be seen in Table \ref{tab:cpu-gpu} and Figure \ref{fig:cpu-gpu}, running the scripts on GPU is much faster than CPU, especially as the dataset size increases.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Dataset Size} & \textbf{CPU - single threaded} & \textbf{CPU - multi threaded} & \textbf{GPU} \\ \hline
\textbf{50 MB}  & 0:01:09 & 0:01:41 & 0:01:08 \\ \hline
\textbf{100 MB} & 0:02:01 & 0:03:23 & 0:01:17 \\ \hline
\textbf{500 MB} & 0:11:24 & 0:09:12 & 0:06:08 \\ \hline
\end{tabular}
\caption{Optimization time for small search space among different processing options}
\label{tab:cpu-gpu}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\hsize]{figures/efficiency/cpu-gpu.pdf}
\caption{Line graph of optimization times of different processing options}
\label{fig:cpu-gpu}
\end{figure}

It is clear that hyperparameter optimization will take less time using GPU, so the further tests to estimate how long the full run will take will only be done on GPUs.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Dataset Size} & \textbf{small search space} & \textbf{full search space} \\ \hline
\textbf{50 MB}        & 0:01:08                     & 0:12:38                    \\ \hline
\textbf{100 MB}       & 0:01:17                     & 0:16:18                    \\ \hline
\textbf{500 MB}       & 0:06:08                     & 1:18:08                    \\ \hline
\end{tabular}
\caption{Optimization times for GPU, small vs full search space}
\label{tab:gpu-search-spaces}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width = 0.8\hsize]{figures/efficiency/gpu.pdf}
\caption{Line graph of optimization times for GPU, small vs full search space}
\label{fig:gpu}
\end{figure}

The full dataset is 12.6 GB, approximately 25 times the large dataset. The trend is pretty linear, so optimization for full dataset for 1 feature is expected to take around 32.5 hours. If all of the features take same of amount of time for optimization, All of the 18 features would take 585 hours, which is around 24.4 days.

Each feature is independent from each other, and running them on the same script does optimizations back to back in series. Each feature can be run on separate compute instances to save a lot of time. Assuming there is no starting fee for computing instances, and only per hour fees, this wouldn’t add much in cost either.

\subsubsection{Conclusion}
The hypothesis was true, GPU takes shorter in bigger datasets, and the gap is expected to grow in even bigger datasets.

From the results of this experiment, running the full dataset for all features is expected to take around 24.4 days on a single compute, but they can also be run on separate compute instances to save time with no considerable drawback.

\subsubsection{Next Step}
The full optimization and training runs for all 18 features will be run on multiple Azure Cloud GPUs in parallel.

\section{Optimized Models}

After the efficiency tests were completed and GPU was chosen as the choice of processing unit, the full optimization and training run was started. T-DAB has received credits from Microsoft that can be spent on Azure ML platform for Innovation use. Therefore, the default NVIDIA Tesla K80 GPUs available on Azure ML platform were used to optimize and train the models. The result of the efficiency test points that multiple GPUs can be used in parallel. The maximum number of GPUs in the innovation account quota was used and the models were trained on 3 seperate NVIDIA Tesla K80 GPUs.

18 models were trained for 18 features. The error rates of the optimized models can be seen in Table \ref{tab:opt-model}, compared to the error rates of Charles' best performing models. The new models were trained and tested on the larger \textit{Atlantic} dataset, whereas Charles' models were trained and tested on the smaller \textit{DHREAM 18} dataset. Thus it is not a one to one comparison, and because the optimized models were trained and tested on a larger dataset with a more variaty of conditions, we might even expect larger error rates. Nevertheless many of the features have same or lower error rates, which is a great success, except from Pitch, AWA\_cos, AWA\_sin, and VMG models that have higher error rates.

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Feature} &
  \textbf{Model} &
  \textbf{MAE} &
  \textbf{RMSE} \\ \hline
AWS &
  \begin{tabular}[c]{@{}l@{}}Model 2\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.220\\ 0.614\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.748\\ 0.785\end{tabular} \\ \hline
Yaw\_cos &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.007\\ 0.007\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.051\\ 0.023\end{tabular} \\ \hline
Yaw\_sin &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.040\\ 0.021\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.053\\ 0.034\end{tabular} \\ \hline
Pitch &
  \begin{tabular}[c]{@{}l@{}}Model 2\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.641\\ 1.367\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.058\\ 1.822\end{tabular} \\ \hline
AWA\_cos &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.028\\ 0.040\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.037\\ 0.056\end{tabular} \\ \hline
AWA\_sin &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.021\\ 0.031\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.037\\ 0.045\end{tabular} \\ \hline
Roll &
  \begin{tabular}[c]{@{}l@{}}Model 2\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.390\\ 1.470\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}2.002\\ 1.910\end{tabular} \\ \hline
Heading\_ov\_ground\_cos &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.037\\ 0.011\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.076\\ 0.025\end{tabular} \\ \hline
Heading\_ov\_ground\_sin &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.020\\ 0.013\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.044\\ 0.048\end{tabular} \\ \hline
Speed\_ov\_ground &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.820\\ 0.132\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.154\\ 0.205\end{tabular} \\ \hline
Heading\_Mag\_cos &
  \begin{tabular}[c]{@{}l@{}}-\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}-\\ 0.016\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}-\\ 0.024\end{tabular} \\ \hline
Heading\_Mag\_sin &
  \begin{tabular}[c]{@{}l@{}}-\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}-\\ 0.014\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}-\\ 0.023\end{tabular} \\ \hline
VMG &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.520\\ 0.767\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.866\\ 1.100\end{tabular} \\ \hline
TWA\_cos &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.026\\ 0.022\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.036\\ 0.030\end{tabular} \\ \hline
TWA\_sin &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.021\\ 0.016\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.034\\ 0.024\end{tabular} \\ \hline
Speed\_ov\_surface &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.200\\ 0.231\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}1.846\\ 0.347\end{tabular} \\ \hline
Heading\_True\_cos &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.017\\ 0.010\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.045\\ 0.018\end{tabular} \\ \hline
Heading\_True\_sin &
  \begin{tabular}[c]{@{}l@{}}Model 1\\ optimized\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.017\\ 0.012\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}0.038\\ 0.020\end{tabular} \\ \hline
\end{tabular}
\caption{Charles' best performing models vs new optimized models}
\label{tab:opt-model}
\end{table}

The efficiency test results suggested that the optimization would take around 34.5 hours for every feature. In the original scripts and during the efficiency tests, there were logging messages about GPU jobs, printing hundreds of times each second to console. Printing has a surprising effect on time taken by a program, more than a novice engineer might expect. Before starting the runs on Azure cloud GPUs, these logging prints were removed. 

In the resulting models, the average optimization duration was 29:01:16, minimum was 16:11:35, and maximum was 41:46:53. A box whisker plot of the optimization times, compared to the estimated time from the efficiency tests can be seen in Figure \ref{fig:opt-time}. As expected, the range is pretty high due to randomness in Bayesian randomness. However, judging from the plot, the estimated time was accurate and removing the excessive log prints were effective.

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\hsize]{figures/Contribution/Opt-time-box-whisker.png}
\caption{Optimization time box-whisker plot compared to estimated time(orange)}
\label{fig:opt-time}
\end{figure}

The full details of the runs, including optimization times, training times, error metrics, and the resulting hyperparameters for all features can be found in appendix.

\section{Transferability Experiment} \label{section:transferability}

This section is about the Transferability Experiment conducted to see how well the models trained on one dataset can predict the boat features using data from another dataset.

\subsubsection{Current Information}
\begin{itemize}
  \item Each dataset belongs to another race/boat transfer, so the sea, wind and the boat trim conditions are different.
  \item The new, optimized models were trained on the \textit{Atlantic} dataset, which were recorded by nke instruments and software.
  \item Charles have previously tested and found that the models trained on one dataset are not transferable to another dataset recorded on the same boat with a different electronics system.
\end{itemize}

\subsubsection{Hypothesis}
The new models have optimized hyperparameters and were trained on a larger dataset.
\begin{itemize}
  \item \textbf{Hypothesis 1:} The new models will be able to predict the boat states of another dataset that were recorded on the same boat with the same electronics system, with a similar error rate.
  \item \textbf{Hypothesis 2:} The new models will be able to predict the boat states of another dataset that were recorded on the same boat with the same electronics system, with a similar error rate, on the sections that have similar environmental conditions.
\end{itemize}

\subsubsection{Assumptions}
Charles' suggested essential features describing the physical environment, which are: True Wind Speed, True Wind Angle, Apparent Wind Angle, and Pitch, provide an accurate and sufficient description of the environment. More information about these essential features can be found in the appendix.

\subsubsection{Experimental set up and methods}
To test this hypothesis, we need a dataset which was recorded on the same boat with the same electronics system and format as the \textit{Atlantic} dataset the models were trained on. Looking at Figure \ref{tab:datasets-practical} in the Available Datasets Section, we can see that the \textit{RDR\_nkz} dataset, suits these requirements. Thus it was chosen as the dataset to make the experiments.

To test both of the hypotheses, A new dataset was created, named \textit{RDR\_nkz (Atlantic conditions)}, by selecting parts from the RDR\_nkz dataset, which have the mentioned four essential features in the range of what is present in the \textit{Atlantic} dataset. For a detailed explanation of how \textit{RDR\_nkz (Atlantic conditions)} was created, see Appendix.


\subsubsection{Results}

The error rates for each feature can be seen in Table \ref{tab:transferability} and the average error rates for different testing datasets is available in Figure \ref{fig:transferability-avg-chart}.

The error rates on \textit{RDR\_nkz} dataset are over four times the rates on the \textit{Atlantic} dataset. Moreover, the error rates of \textit{RDR\_nkz (Atlantic conditions)}, which was created to have similar conditions to the \textit{Atlantic} dataset, are even higher than the full \textit{RDR\_nkz} dataset.

\begin{table}[htbp]
\centering
\rowcolors{2}{gray!20}{white}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|r|}{\textbf{Test Set:}} &
  \multicolumn{2}{c|}{\textbf{Atlantic}} &
  \multicolumn{2}{c|}{\textbf{RDR\_nkz}} &
  \multicolumn{2}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}RDR\_nkz\\ (Atlantic \\ conditions)\end{tabular}}} \\ \hline
                         & MAE   & RMSE  & MAE   & RMSE  & MAE   & RMSE  \\ \hline
AWS                      & 0.614 & 0.785 & 10.44 & 11.48 & 13.11 & 13.83 \\ \hline
Yaw\_cos                 & 0.007 & 0.023 & 0.025 & 0.029 & 0.025 & 0.030 \\ \hline
Yaw\_sin                 & 0.021 & 0.034 & 0.165 & 0.182 & 0.221 & 0.231 \\ \hline
Pitch                    & 1.367 & 1.822 & 6.697 & 7.643 & 9.904 & 10.39 \\ \hline
AWA\_cos                 & 0.040 & 0.056 & 0.175 & 0.242 & 0.073 & 0.095 \\ \hline
AWA\_sin                 & 0.031 & 0.045 & 0.134 & 0.170 & 0.085 & 0.111 \\ \hline
Roll                     & 1.470 & 1.910 & 7.589 & 8.998 & 11.76 & 12.40 \\ \hline
Heading\_ov\_ground\_cos & 0.011 & 0.025 & 0.193 & 0.251 & 0.099 & 0.113 \\ \hline
Heading\_ov\_ground\_sin & 0.013 & 0.048 & 0.538 & 0.699 & 0.518 & 0.707 \\ \hline
Speed\_ov\_ground  & 0.132 & 0.205 & 2.094 & 2.367 & 2.580 & 2.742 \\ \hline
Heading\_Mag\_cos  & 0.016 & 0.024 & 0.289 & 0.407 & 0.167 & 0.216 \\ \hline
Heading\_Mag\_sin  & 0.014 & 0.023 & 0.357 & 0.391 & 0.357 & 0.407 \\ \hline
VMG                & 0.767 & 1.100 & 3.917 & 4.379 & 2.276 & 2.698 \\ \hline
TWA\_cos           & 0.022 & 0.030 & 0.118 & 0.140 & 0.111 & 0.125 \\ \hline
TWA\_sin           & 0.016 & 0.024 & 0.137 & 0.159 & 0.213 & 0.226 \\ \hline
Speed\_ov\_surface & 0.231 & 0.347 & 2.433 & 2.746 & 3.644 & 3.820 \\ \hline
Heading\_True\_cos & 0.010 & 0.018 & 0.153 & 0.225 & 0.080 & 0.103 \\ \hline
Heading\_True\_sin & 0.012 & 0.020 & 0.320 & 0.412 & 0.357 & 0.458 \\ \hline
\end{tabular}
\caption{Full error rate data of the transferability experiment for all features}
\label{tab:transferability}
\end{table}


\begin{figure}[htbp]
\centering
\includegraphics[width = \hsize]{figures/transferability/transferability chart.png}
\caption{Average error rates on different testsets}
\label{fig:transferability-avg-chart}
\end{figure}

\subsubsection{Conclusion}
Both of the hypotheses were wrong, as the models trained on the \textit{Atlantic} dataset have drastically higher error rates on both the \textit{RDR\_nkz} dataset, which was recorded on the same boat and same electronics system; and on the \textit{RDR\_nkz (Atlantic conditions)} dataset, which also have similar environmental conditions.

A further takeaway is that the Charles' suggested essential features describing the physical environment are not sufficient for transferability among datasets, as the error rates of \textit{RDR\_nkz (Atlantic conditions)} are higher than \textit{RDR\_nkz} error rates.

\subsubsection{Next Step}
The state estimator models we have can only predict succesfully on \textit{Atlantic} data. Therefore in the RL environment that will be created, the data from \textit{Atlantic} dataset will be used.

\section{RL Framework}
After the Background Research, the planned Reinforcement Learning framework to use was OpenAI's Spinning Up framework. They provide clean implementations of modern RL algorithms, and a basic interface to apply the algorithms to OpenAI Gym environments, then plot the results. However, OpenAI Spinning Up has some downsides and lack some important features that would be helpful during this project.

\subsection{RL Algorithm Implementation Differences} \label{RLF:imp-diff}
Spinning Up's main focus is education. Therefore the algorithm implementations are stripped down from the proposed versions from the original papers, so the algorithms would be easier to read and understand. Although this is good for education, the resulting algorithms do not perform up to their potential due to their simplicity. The performance of SAC which is the algorithm of choice for this project, used on different Gym environments can be seen in Figure \ref{fig:spinup-SAC}.

\begin{figure}[h]
     \centering
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/rl-framework/sac-pendulum.png}
         \caption{Pendulum-v0 (Very Easy)}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/rl-framework/sac-mountain-car.png}
         \caption{MountainCarContinuous-v0 (Easy)}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/rl-framework/sac-bipedal-walker.png}
         \caption{BipedalWalker-v3 (Hard)}
     \end{subfigure}
        \caption{Performance of Spinning Up implementation of SAC on different environments, using default parameters}
        \label{fig:spinup-SAC}
\end{figure}

Spinning Up implementation performs well and converges quickly on easy environments, but it provides disappointing results on the harder BipedalWalker-v3 environment. SAC is expected to have better exploration and achieve better results on BipedalWalker-v3 environment before 300.000 environment interacts \cite{gym-leaderboard}. But it never managed to escape a local minimum for a long period of training time. Considering our sailing environment will be pretty complex, Spinning Up implementation of SAC is not suitable for use on this project.

\subsection{RL Framework Features} \label{RLF:framework-features}

\begin{wrapfigure}{r}{0.4\textwidth}
\vspace{-4em}
\centering
\includegraphics[width = 0.39\textwidth]{figures/rl-framework/hyperparameter-ddpg.png}
\caption{DDPG on Walker2d-v1 with random hyperparameters \cite{hyperparameter-ddpg}}
\label{fig:hyperparameter-ddpg}
\vspace{-1em}
\end{wrapfigure}

Spinning Up Framework lacks some important features for Reinforcement Learning. First, it does not support continuing training of a previously trained agents. This is problematic in a few ways: it costs precious time and resources to train agents from scratch every time, plus even if models are trained again from ground up, no two reinforcement learning runs will be identical because of the noise or stochasticity in the algorithms.

The second lacking feature is that there is no hyperparameter optimization support. Hyperparameters can cause huge difference in performance \cite{hyperparameter-ddpg}. A comparison of DDPG on Walker2d-v1 with random hyperparameters can be seen in Figure \ref{fig:hyperparameter-ddpg}. The best and worst performing hyperparameters have approximately 3-fold average reward difference after 1 million timesteps.

Both of these features, and probably more that will arise in the future are important for this project, so another framework with these additional features is needed.


\subsection{Stable Baselines 3}
Stable Baselines3 (SB3) is a library providing reliable implementations of state-of-the-art reinforcement learning algorithms in PyTorch, complete with a training framework 'RL Baselines3 Zoo' which contains scripts for training, evaluating agents, tuning hyperparameters, plotting results, and recording videos \cite{stable-baselines3}.

SB3 solves both of the problems of Spinning Up Framework mentioned in sections \ref{RLF:imp-diff} and \ref{RLF:framework-features}. SB3 is focused on providing reliable implementations that can be used on Deep Reinforcement Learning Research, instead of an education focus of Spinning Up. SB3 implementations are fully functional, high quality, and they match the results of best previous implementations. A performance comparison of Soft Actor Critic implementations of Stable Baselines3 and OpenAI Spinning Up can be seen in Figure \ref{fig:spinup-vs-sb3}. We are expecting SAC to converge to 300 score which is the goal of this environment \cite{Bipedal-Walker-v2} in around 300.000 steps \cite{gym-leaderboard}. Stable Baselines3 implementation delivers expected results whereas the Spinning Up implementation falls short. The hyperparamaters were tuned in SB3 implementations, but weren't tuned for Spinning Up as it doesn't support hyperparameter tuning.

\begin{figure}[h]
     \centering
     \begin{subfigure}[t]{0.49\textwidth}
         \centering
         \includegraphics[width=0.91\textwidth]{figures/rl-framework/sac-bipedal-walker.png}
         \caption{Spinning Up implementation (Default parameters) - Goal not achieved in 400.000 steps}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/rl-framework/sb3-sac-BipedalWalker-v3.png}
         \caption{Stable Baselines3 implementation (Tuned parameters) - Goal Achieved in 200.000 steps}
     \end{subfigure}
        \caption{Training Performance of SAC implementations. Goal Score: 300}
        \label{fig:spinup-vs-sb3}
\end{figure}

Moreover, the RL Baselines Zoo has the missing features of Spinning Up's training framework, namely hyperparameter optimization and continuing training of previously trained models \cite{rl-zoo3}. Therefore, SB3 will be the choice of RL Framework.


\section{Gym Environment Implementation}

\subsection{Available data and Environment Constraints}
We do not have information about

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\chapter{Experimental Results}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\chapter{Conclusion}

\section{Future Work}
add tack detection to pipeline


%% bibliography
\bibliographystyle{unsrt}
%\setlength\bibsep{3pt}
\bibliography{bibliography}


%% appendix
\appendix
\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}

\chapter{Sail Trim Approach}
\input{Chapters/appendix-sailtrim}

\chapter{Azure Cloud Run Details}
\input{Chapters/gpu-run-details}

\chapter{Charles' Suggested Features Describing the Environment}
\input{Chapters/appendix-4-essential-features}

\chapter{Creating the RDR\_nkz(Atlantic Conditions) Dataset}
\input{Chapters/appendix-RDR-nkz-atlantic-conditions}


\end{document}
